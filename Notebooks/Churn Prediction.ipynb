{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83840256-77c9-4a7c-aaef-7f9321d6dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, log_loss, matthews_corrcoef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ade3aa-0311-41ca-b287-e28cea53baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    'State': 'category',\n",
    "    'Area code': 'category',\n",
    "    'Churn': int\n",
    "}\n",
    "\n",
    "train_df = pd.read_csv('churn-bigml-80.csv', dtype=dtype)\n",
    "test_df = pd.read_csv('churn-bigml-20.csv', dtype=dtype)\n",
    "full_df = pd.concat([train_df, test_df])\n",
    "\n",
    "train_len, test_len = len(train_df), len(test_df)\n",
    "full_df['International plan'] = (full_df['International plan'] == 'Yes')\n",
    "full_df['Voice mail plan'] = (full_df['Voice mail plan'] == 'Yes')\n",
    "\n",
    "train_df = full_df[:train_len]\n",
    "test_df = full_df[:test_len]\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9031c732-b24d-4954-a6ed-60478fef24e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_df.iloc[:, :-1]\n",
    "y = full_df.Churn\n",
    "full_df.Churn.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fafa616-cbde-4ad8-98ba-3cf51089ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.get_dummies(X, columns=['State', 'Area code'])\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065615e7-4642-4cb2-ab3b-f4d3460a4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y)\n",
    "\n",
    "#  Checking the shape of the split\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# Checking churn proportions\n",
    "print(y_train.value_counts(1))\n",
    "print(y_test.value_counts(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1879ba-3604-4218-8746-88661f305cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_weight = (y_train.size - y_train.sum()) / y_train.sum()\n",
    "\n",
    "clf = xgb.XGBClassifier(\n",
    "    seed = 42,\n",
    "    early_stopping_rounds=10,\n",
    "    eval_metric=\"auc\",\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    verbose=True,\n",
    "    eval_set=[(X_test, y_test)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6df8b6-ad83-4ac5-a733-0afe1a99c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(confusion_matrix):\n",
    "    report = classification_report(y_test, predictions, output_dict=True)\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    mcc = matthews_corrcoef(y_test, predictions)\n",
    "    \n",
    "    metrics_dict = {\n",
    "        'Accuracy': [accuracy],\n",
    "        'MCC': [mcc],\n",
    "        'Sensitivity': [report['1']['recall']],\n",
    "        'Specificity': [report['0']['recall']],\n",
    "        'Precision': [report['1']['precision']],\n",
    "        'F1-Score': [report['1']['f1-score']]\n",
    "    }\n",
    "    metrics_df = pd.DataFrame(metrics_dict)\n",
    "    return metrics_df\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cmn, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "calculate_metrics(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071eab3b-ab7e-4317-b321-6584a7d1b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the search space for hyperparameters\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "    }\n",
    "\n",
    "    # Set the scale_pos_weight value\n",
    "    scale_pos_weight = (y_train.size - y_train.sum()) / y_train.sum()\n",
    "    \n",
    "    # Instantiate the classifier\n",
    "    clf = xgb.XGBClassifier(\n",
    "        seed=42,\n",
    "        early_stopping_rounds=10,\n",
    "        eval_metric=\"auc\",\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    # Train the classifier\n",
    "    clf.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        verbose=False,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "    )\n",
    "    \n",
    "    # Predict probabilities\n",
    "    y_pred_prob = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate and return the AUC-ROC score as the optimization target\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    return auc\n",
    "\n",
    "# Create the Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Get the best hyperparameters and the best AUC-ROC score\n",
    "best_params = study.best_params\n",
    "best_auc = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best AUC-ROC Score:\", best_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a123806-77b0-4787-b46e-3021de9ae8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier\n",
    "clf = xgb.XGBClassifier(\n",
    "    seed=42,\n",
    "    early_stopping_rounds=10,\n",
    "    eval_metric=\"auc\",\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    verbose=False,\n",
    "    eval_set=[(X_test, y_test)],\n",
    ")\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cmn, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "calculate_metrics(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98781ec8-bb9f-4589-92e3-63a5b6f38165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
